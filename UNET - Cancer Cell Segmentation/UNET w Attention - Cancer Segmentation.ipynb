{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install -U segmentation-models-3D\n",
    "# !pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import splitfolders\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical # multiclass semantic segmentation, therefore the volumes to categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = './MICCAI_BraTS2020_TrainingData/'\n",
    "\n",
    "test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
    "test_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "test_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
    "test_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
    "test_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_image_flair[:, :, n_slice], cmap='gray')\n",
    "plt.title('Flair Scan')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_image_t1[:, :, n_slice], cmap='gray')\n",
    "plt.title('T1 Scan')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(test_image_t1ce[:, :, n_slice], cmap='gray')\n",
    "plt.title('T1ce Scan')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_image_t2[:, :, n_slice], cmap='gray')\n",
    "plt.title('T2 Scan')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_x = np.stack([test_image_flair, test_image_t1ce, test_image_t2], axis=3)\n",
    "combined_x = combined_x[56:184, 56:184, 13:141] #crop to 128 x 128 x 128 X 3\n",
    "\n",
    "test_mask = test_mask[56:184, 56:184, 13:141]\n",
    "n_slice = random.randint(0, test_mask.shape[1])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(combined_x[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title('Flair Scan')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(combined_x[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('T1ce Scan')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(combined_x[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title('T2 Scan')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "print(K.int_shape(test_image_flair))\n",
    "\n",
    "print(K.int_shape(combined_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH='./MICCAI_BraTS2020_TrainingData/'\n",
    "flair_list = sorted(glob.glob(DATASET_PATH+'**/*_flair.nii'))\n",
    "t1_list = sorted(glob.glob(DATASET_PATH + '**/*_t1.nii'))\n",
    "t1ce_list = sorted(glob.glob(DATASET_PATH + '**/*_t1ce.nii'))\n",
    "t2_list = sorted(glob.glob(DATASET_PATH + '**/*_t2.nii'))\n",
    "mask_list = sorted(glob.glob(DATASET_PATH + '**/*_seg.nii'))\n",
    "\n",
    "for img in range(len(flair_list)):\n",
    "  print('Now processing image and masks no: ', img)\n",
    "  print(flair_list[img])\n",
    "  temp_image_flair = nib.load(f'{flair_list[img]}').get_fdata()\n",
    "  temp_image_flair = scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "\n",
    "  temp_image_t1 = nib.load(f'{t1_list[img]}').get_fdata()\n",
    "  temp_image_t1 = scaler.fit_transform(temp_image_t1.reshape(-1, temp_image_t1.shape[-1])).reshape(temp_image_t1.shape)\n",
    "\n",
    "  temp_image_t1ce = nib.load(f'{t1ce_list[img]}').get_fdata()\n",
    "  temp_image_t1ce = scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "\n",
    "  temp_image_t2 = nib.load(f'{t2_list[img]}').get_fdata()\n",
    "  temp_image_t2 = scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "\n",
    "  temp_mask = nib.load(f'{mask_list[img]}').get_fdata()\n",
    "  temp_mask = temp_mask.astype(np.uint8)\n",
    "  temp_mask[temp_mask == 4] = 3\n",
    "\n",
    "  temp_combined_images = np.stack([temp_image_flair, temp_image_t1, temp_image_t1ce, temp_image_t2], axis = 3)\n",
    "  temp_combined_images = temp_combined_images[56:184, 56:184, 13:141]\n",
    "  temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "  val, counts = np.unique(temp_mask, return_counts=True)\n",
    "\n",
    "  if(1 - (counts[0]/counts.sum())) > 0.01:\n",
    "    temp_mask = to_categorical(temp_mask, num_classes=4)\n",
    "    np.save(DATASET_PATH + 'final_dataset/scans/image_' + str(img) + '.npy', temp_combined_images)\n",
    "    np.save(DATASET_PATH + 'final_dataset/masks/image_' + str(img) + '.npy', temp_mask)\n",
    "    print(\"Saved\")\n",
    "  else:\n",
    "    print(\"Not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = DATASET_PATH + 'final_dataset/'\n",
    "output_folder = DATASET_PATH + 'split_dataset/'\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.6, .2, .2), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_img(img_dir, img_list):\n",
    "  images=[]\n",
    "  for i, image_name in enumerate(img_list):\n",
    "    if(image_name.split('.')[1] == 'npy'):\n",
    "      image = np.load(img_dir + image_name)\n",
    "      images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
    "  L = len(img_list)\n",
    "  # keras needs the generator infinite, so use while True\n",
    "  while True:\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "\n",
    "    while batch_start < L:\n",
    "      limit = min(batch_end, L)\n",
    "      X = load_img(img_dir, img_list[batch_start:limit])\n",
    "      Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
    "\n",
    "      yield(X, Y) # a tuple with two numpy arrays with batch_size samples\n",
    "\n",
    "      batch_start += batch_size\n",
    "      batch_end += batch_size\n",
    "\n",
    "\n",
    "# Test the generator\n",
    "TRAIN_DATASET_PATH = './MICCAI_BraTS2020_TrainingData/split_dataset/train/'\n",
    "train_img_dir = TRAIN_DATASET_PATH + 'scans/'\n",
    "train_mask_dir = TRAIN_DATASET_PATH + 'masks/'\n",
    "\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list,\n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "# Verify generator - In python 3 next() is renamed as __next__()\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "img_num = random.randint(0, img.shape[0]-1)\n",
    "\n",
    "test_img = img[img_num]\n",
    "test_mask = msk[img_num]\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title('Flair Scan')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('T1ce Scan')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title('T2 Scan')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './MICCAI_BraTS2020_TrainingData/split_dataset/'\n",
    "train_img_dir = DATASET_PATH + 'train/scans/'\n",
    "train_mask_dir = DATASET_PATH + 'train/masks/'\n",
    "\n",
    "val_img_dir = DATASET_PATH + 'val/scans/'\n",
    "val_mask_dir = DATASET_PATH + 'val/masks/'\n",
    "\n",
    "test_img_dir = DATASET_PATH + 'test/scans/'\n",
    "test_mask_dir = DATASET_PATH + 'test/masks/'\n",
    "\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "val_img_list = os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)\n",
    "\n",
    "test_img_list = os.listdir(test_img_dir)\n",
    "test_mask_list = os.listdir(test_mask_dir)\n",
    "\n",
    "batch_size = 2\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list,\n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "val_img_datagen = imageLoader(val_img_dir, val_img_list,\n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "test_img_datagen = imageLoader(test_img_dir, test_img_list,\n",
    "                                test_mask_dir, test_mask_list, batch_size)\n",
    "\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and metrics\n",
    "- These losses and metrics best handle the problem of class imbalance\n",
    "- Used: dice_coef as a metric, tversky_loss as a loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) +\n",
    "                                           smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg +\n",
    "                                  (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return K.pow((1 - tv), gamma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss, metrics and optimizer to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, Activation, add, concatenate, Conv3DTranspose, BatchNormalization, Dropout, UpSampling3D, multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import layers\n",
    "\n",
    "kernel_initializer = 'he_uniform'\n",
    "\n",
    "import segmentation_models_3D as sm\n",
    "\n",
    "metrics = [dice_coef]\n",
    "\n",
    "LR = 0.0001\n",
    "optim = Adam(LR)\n",
    "\n",
    "steps_per_epoch = len(train_img_list) // batch_size\n",
    "val_steps_per_epoch = len(val_img_list) // batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n",
    "  inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "\n",
    "  # Downsampling\n",
    "  c1 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(inputs)\n",
    "  c1 = Dropout(0.1)(c1)\n",
    "  c1 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "  p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "\n",
    "  c2 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "  c2 = Dropout(0.1)(c2)\n",
    "  c2 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "  p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "\n",
    "  c3 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "  p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "\n",
    "  c4 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "  p4 = MaxPooling3D((2, 2, 2))(c4)\n",
    "\n",
    "  c5 = Conv3D(filters = 256, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)\n",
    "  c5 = Dropout(0.3)(c5)\n",
    "  c5 = Conv3D(filters = 256, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)\n",
    "  \n",
    "  # Upsampling part\n",
    "  u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)  \n",
    "    \n",
    "  u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)  \n",
    "  \n",
    "  u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "  c8 = Dropout(0.1)(c8)\n",
    "  c8 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)  \n",
    "\n",
    "  u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "  u9 = concatenate([u9, c1])\n",
    "  c9 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "  c9 = Dropout(0.1)(c9)\n",
    "  c9 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)  \n",
    "\n",
    "  outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_img_list)//batch_size\n",
    "val_steps_per_epoch = len(val_img_list)//batch_size\n",
    "\n",
    "model = UNet(IMG_HEIGHT = 128,\n",
    "              IMG_WIDTH = 128,\n",
    "              IMG_DEPTH = 128,\n",
    "              IMG_CHANNELS = 3,\n",
    "              num_classes = 4)\n",
    "\n",
    "model.compile(optimizer = optim, loss = tversky_loss, metrics = metrics)\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Attention UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core.activation import Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "def repeat_elem(tensor, rep):\n",
    "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
    "    #by a factor of rep.\n",
    "    # If tensor has shape (None, 128,128,3), lambda will return a tensor of shape \n",
    "    #(None, 128,128,6), if specified axis=3 and rep=2.\n",
    "\n",
    "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=4),\n",
    "                          arguments={'repnum': rep})(tensor)\n",
    "\n",
    "def attention_block(x, gating, inter_shape):\n",
    "  shape_x = K.int_shape(x)\n",
    "  shape_g = K.int_shape(gating)\n",
    "\n",
    "  # Getting the gating signal to the same number of filters as the inter_shape\n",
    "  phi_g = Conv3D(filters=inter_shape, kernel_size=1, strides=1, padding='same')(gating)\n",
    "\n",
    "  # Geting the x signal to the same shape as the gating signal\n",
    "  theta_x = Conv3D(filters=inter_shape, kernel_size=3, strides=(\n",
    "      shape_x[1] // shape_g[1],\n",
    "      shape_x[2] // shape_g[2],\n",
    "      shape_x[3] // shape_g[3]\n",
    "  ), padding='same')(x)\n",
    "  shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "  print(shape_theta_x, shape_g)\n",
    "\n",
    "  # Elemet-wise addition of the gating and x signals\n",
    "  xg_sum = add([phi_g, theta_x])\n",
    "  xg_sum = Activation('relu')(xg_sum)\n",
    "\n",
    "  # 1x1x1 convolution\n",
    "  psi = Conv3D(filters=1, kernel_size=1, padding='same')(xg_sum)\n",
    "  sigmoid_psi = Activation('sigmoid')(psi)\n",
    "  shape_sigmoid = K.int_shape(sigmoid_psi)\n",
    "\n",
    "  # Upsampling psi back to the original dimensions of x signal to enable \n",
    "  # element-wise multiplication with the signal\n",
    "\n",
    "  upsampled_sigmoid_psi = UpSampling3D(size=(\n",
    "      shape_x[1] // shape_sigmoid[1], \n",
    "      shape_x[2] // shape_sigmoid[2],\n",
    "      shape_x[3] // shape_sigmoid[3]\n",
    "  ))(sigmoid_psi)\n",
    "\n",
    "  # Expand the filter axis to the number of filters in the original x signal\n",
    "  upsampled_sigmoid_psi = repeat_elem(upsampled_sigmoid_psi, shape_x[4])\n",
    "\n",
    "  # Element-wise multiplication of attention coefficients back onto original x signal\n",
    "  attention_coeffs = multiply([upsampled_sigmoid_psi, x])\n",
    "\n",
    "  # Final 1x1x1 convolution to consolidate attention signal to original  x dimensions\n",
    "  output = Conv3D(filters=shape_x[3], kernel_size=1, strides=1, padding='same')(attention_coeffs)\n",
    "  output = BatchNormalization()(output)\n",
    "  return output\n",
    "\n",
    "\n",
    "# Gating signal\n",
    "def gating_signal(input, output_size, batch_norm=False):\n",
    "  # Resize the down layer feature map into the same dimensions as the up layer feature map using 1x1 conv\n",
    "  # Return: the gating feature map with the same dimension of the up layer feature map\n",
    "  x = Conv3D(output_size, (1, 1, 1), padding='same')(input)\n",
    "  if batch_norm:\n",
    "    x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "# Attention UNet\n",
    "def attention_unet(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes, batch_norm = True):\n",
    "  inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "  FILTER_NUM = 64 #\n",
    "  FILTER_SIZE = 3 #\n",
    "  UP_SAMPLING_SIZE = 2 # \n",
    "\n",
    "  c1 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(inputs)\n",
    "  c1 = Dropout(0.1)(c1)\n",
    "  c1 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "  p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "\n",
    "  c2 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "  c2 = Dropout(0.1)(c2)\n",
    "  c2 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "  p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "\n",
    "  c3 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "  p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "\n",
    "  c4 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "  p4 = MaxPooling3D((2, 2, 2))(c4)\n",
    "\n",
    "  c5 = Conv3D(filters = 256, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(p4)\n",
    "  c5 = Dropout(0.3)(c5)\n",
    "  c5 = Conv3D(filters = 256, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c5)\n",
    "  \n",
    "\n",
    "  gating_6 = gating_signal(c5, 128, batch_norm)\n",
    "  att_6 = attention_block(c4, gating_6, 128)\n",
    "  u6 = UpSampling3D((2, 2, 2), data_format='channels_last')(c5)\n",
    "  u6 = concatenate([u6, att_6])\n",
    "  c6 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv3D(filters = 128, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c6)  \n",
    "    \n",
    "  gating_7 = gating_signal(c6, 64, batch_norm)\n",
    "  att_7 = attention_block(c3, gating_6, 64)\n",
    "  u7 = UpSampling3D((2, 2, 2), data_format='channels_last')(c6)\n",
    "  u7 = concatenate([u7, att_7])\n",
    "  c7 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv3D(filters = 64, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c7)  \n",
    "  \n",
    "  gating_8 = gating_signal(c7, 64, batch_norm)\n",
    "  att_8 = attention_block(c2, gating_6, 64)\n",
    "  u8 = UpSampling3D((2, 2, 2), data_format='channels_last')(c7)\n",
    "  u8 = concatenate([u8, att_8])\n",
    "  c8 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "  c8 = Dropout(0.1)(c8)\n",
    "  c8 = Conv3D(filters = 32, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c8)  \n",
    "\n",
    "  gating_9 = gating_signal(c8, 64, batch_norm)\n",
    "  att_9 = attention_block(c1, gating_6, 64)\n",
    "  u9 = UpSampling3D((2, 2, 2), data_format='channels_last')(c8)\n",
    "  u9 = concatenate([u9, att_9])\n",
    "  c9 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "  c9 = Dropout(0.1)(c9)\n",
    "  c9 = Conv3D(filters = 16, kernel_size = 3, strides = 1, activation=LeakyReLU(alpha=0.1), kernel_initializer=kernel_initializer, padding='same')(c9)  \n",
    "\n",
    "  outputs = Conv3D(num_classes, (1, 1, 1))(c9)\n",
    "  outputs = BatchNormalization()(outputs)\n",
    "  outputs = Activation('softmax')(outputs)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs], name=\"Attention_UNet\")\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_img_list)//batch_size\n",
    "val_steps_per_epoch = len(val_img_list)//batch_size\n",
    "\n",
    "model = attention_unet(IMG_HEIGHT = 128,\n",
    "              IMG_WIDTH = 128,\n",
    "              IMG_DEPTH = 128,\n",
    "              IMG_CHANNELS = 3,\n",
    "              num_classes = 4)\n",
    "\n",
    "model.compile(optimizer = optim, loss = tversky_loss, metrics = metrics)\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TerminateOnNaN\n",
    "\n",
    "checkpoint_path = ''\n",
    "log_path = ''\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1,\n",
    "                      monitor='val_loss',\n",
    "                      patience=4,\n",
    "                      min_lr=0.0001,\n",
    "                      verbose=1,\n",
    "                      mode='min'),\n",
    "    ModelCheckpoint(checkpoint_path,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    verbose=0,\n",
    "                    save_best_only=True),\n",
    "    CSVLogger(log_path, separator=',', append=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "history = model.fit(train_img_datagen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_img_datagen,\n",
    "                    validation_steps=val_steps_per_epoch,\n",
    "                    callbacks=callbacks\n",
    "                    )\n",
    "\n",
    "history_callback = np.save('', history.history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "my_model = load_model('', custom_objects={\n",
    "    'tversky_loss': tversky_loss,\n",
    "    'dice_coef': dice_coef},\n",
    "    compile = True)\n",
    "\n",
    "# Verify IoU on a batch of images from the test dataset\n",
    "batch_size = 8\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list,\n",
    "                               val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "\n",
    "results = my_model.evaluate(test_image_batch, test_mask_batch, batch_size=batch_size)\n",
    "print(\"test acc, test loss:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a test scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "my_model = load_model('', compile=False)\n",
    "\n",
    "img_num = 53\n",
    "test_scan = np.load('' + str(img_num) + '.npy')\n",
    "\n",
    "test_mask = np.load('' + str(img_num) + '.npy')\n",
    "test_mask_argmax = np.argmax(test_mask, axis = 3)\n",
    "\n",
    "test_scan_input = np.expand_dims(test_scan, axis = 0)\n",
    "test_prediction = my_model.predict(test_scan_input)\n",
    "test_prediction_argmax = np.argmax(test_prediction, axis = 4)[0, :, :, :]\n",
    "     \n",
    "\n",
    "# n_slice = 55\n",
    "n_slice = random.randint(0, test_mask_argmax.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_scan[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('Testing Scan')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_mask_argmax[:, :, n_slice])\n",
    "plt.title('Testing Label')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_prediction_argmax[:, :, n_slice])\n",
    "plt.title('Prediction on test image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
